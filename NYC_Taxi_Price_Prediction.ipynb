{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff109dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berkedenizbozyigit/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/NYCTaxiFares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9917e1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021aaaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d82e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>2010-04-18 14:33:03 UTC</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.955857</td>\n",
       "      <td>40.784590</td>\n",
       "      <td>-73.981941</td>\n",
       "      <td>40.736789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2010-04-23 10:27:48 UTC</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.996329</td>\n",
       "      <td>40.772727</td>\n",
       "      <td>-74.049890</td>\n",
       "      <td>40.740413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2010-04-18 18:50:40 UTC</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.988574</td>\n",
       "      <td>40.749772</td>\n",
       "      <td>-74.011541</td>\n",
       "      <td>40.707799</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2010-04-13 08:14:44 UTC</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.004449</td>\n",
       "      <td>40.724529</td>\n",
       "      <td>-73.992697</td>\n",
       "      <td>40.730765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2010-04-17 16:00:14 UTC</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.955415</td>\n",
       "      <td>40.771920</td>\n",
       "      <td>-73.967623</td>\n",
       "      <td>40.763015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "119995  2010-04-18 14:33:03 UTC         15.3           1        -73.955857   \n",
       "119996  2010-04-23 10:27:48 UTC         15.3           1        -73.996329   \n",
       "119997  2010-04-18 18:50:40 UTC         12.5           1        -73.988574   \n",
       "119998  2010-04-13 08:14:44 UTC          4.9           0        -74.004449   \n",
       "119999  2010-04-17 16:00:14 UTC          5.3           0        -73.955415   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "119995        40.784590         -73.981941         40.736789                1  \n",
       "119996        40.772727         -74.049890         40.740413                1  \n",
       "119997        40.749772         -74.011541         40.707799                3  \n",
       "119998        40.724529         -73.992697         40.730765                1  \n",
       "119999        40.771920         -73.967623         40.763015                3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfd072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de394620",
   "metadata": {},
   "source": [
    " ## Calculate the distance traveled\n",
    "The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{split}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2c204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4612998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e824568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      " 8   dist_km            120000 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5529d737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1f7c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1e142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-24 23:59:42')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f401f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ff0e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                          int64\n",
       "AMorPM                       object\n",
       "Weekday                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf4922d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1a3f365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6b3404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4985de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec102931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11,  7, ..., 14,  4, 12], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39db5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.stack([hr,ampm,wkdy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66686363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       ...,\n",
       "       [14,  1,  3],\n",
       "       [ 4,  0,  5],\n",
       "       [12,  1,  2]], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcc9bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c916655",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = torch.tensor(cats,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93f7f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts =np.stack([df[col].values for col in cont_cols],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "581e4eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40.730521  , -73.992365  ,  40.744746  , -73.975499  ,\n",
       "          1.        ,   2.12631159],\n",
       "       [ 40.740558  , -73.990078  ,  40.744114  , -73.974232  ,\n",
       "          1.        ,   1.39230687],\n",
       "       [ 40.751118  , -73.994149  ,  40.766235  , -73.960064  ,\n",
       "          2.        ,   3.32676344],\n",
       "       ...,\n",
       "       [ 40.749772  , -73.988574  ,  40.707799  , -74.011541  ,\n",
       "          3.        ,   5.05252282],\n",
       "       [ 40.724529  , -74.004449  ,  40.730765  , -73.992697  ,\n",
       "          1.        ,   1.20892296],\n",
       "       [ 40.77192   , -73.955415  ,  40.763015  , -73.967623  ,\n",
       "          3.        ,   1.42739869]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2037babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = torch.tensor(conts, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "018e671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        ...,\n",
       "        [ 40.7498, -73.9886,  40.7078, -74.0115,   3.0000,   5.0525],\n",
       "        [ 40.7245, -74.0044,  40.7308, -73.9927,   1.0000,   1.2089],\n",
       "        [ 40.7719, -73.9554,  40.7630, -73.9676,   3.0000,   1.4274]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c451c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df[y_col].values,dtype=torch.float).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "739f3b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "186a30b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac466425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca8ce791",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_size = [len(df[col].cat.categories) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bd46ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 2, 7]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c583a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = [(size,min(50,(size+1)//2)) for size in cat_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4860e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29a941a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catz = cats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "872e5488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c627aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfembeds = nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in emb_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3298a3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5387c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingz = []\n",
    "\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "183328f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.0325, -1.7337, -0.3517, -0.2156,  1.6509, -0.3791,  0.2631,  1.5028,\n",
       "          -0.7700,  0.7409,  0.4534, -0.3521],\n",
       "         [ 0.4867,  0.7857,  1.3771, -1.2154,  1.7635, -0.5119,  0.5086,  0.3139,\n",
       "          -1.9364,  0.4130, -0.2340, -0.2923],\n",
       "         [-0.4232,  0.1812, -1.8287, -0.3087, -0.4148, -0.3767, -0.0333,  0.8867,\n",
       "           0.3249, -0.6121, -0.3356, -1.5467],\n",
       "         [-0.0143, -1.0927, -0.1606, -2.6754, -0.1541,  0.2564, -0.0149,  1.9968,\n",
       "           0.9542, -0.8564, -0.9792, -0.7682]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.9647],\n",
       "         [-0.9647],\n",
       "         [-0.9647],\n",
       "         [ 1.0592]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 2.7707,  0.4532, -0.4428,  1.1758],\n",
       "         [ 0.6174, -0.0273,  1.0741,  1.3366],\n",
       "         [ 0.6174, -0.0273,  1.0741,  1.3366],\n",
       "         [-0.7031, -0.0180, -0.1402, -0.6719]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "423b1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0325, -1.7337, -0.3517, -0.2156,  1.6509, -0.3791,  0.2631,  1.5028,\n",
       "         -0.7700,  0.7409,  0.4534, -0.3521, -0.9647,  2.7707,  0.4532, -0.4428,\n",
       "          1.1758],\n",
       "        [ 0.4867,  0.7857,  1.3771, -1.2154,  1.7635, -0.5119,  0.5086,  0.3139,\n",
       "         -1.9364,  0.4130, -0.2340, -0.2923, -0.9647,  0.6174, -0.0273,  1.0741,\n",
       "          1.3366],\n",
       "        [-0.4232,  0.1812, -1.8287, -0.3087, -0.4148, -0.3767, -0.0333,  0.8867,\n",
       "          0.3249, -0.6121, -0.3356, -1.5467, -0.9647,  0.6174, -0.0273,  1.0741,\n",
       "          1.3366],\n",
       "        [-0.0143, -1.0927, -0.1606, -2.6754, -0.1541,  0.2564, -0.0149,  1.9968,\n",
       "          0.9542, -0.8564, -0.9792, -0.7682,  1.0592, -0.7031, -0.0180, -0.1402,\n",
       "         -0.6719]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We concatenate the embedding sections (12,1,4) into one (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7266e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was assigned under the __init__() method\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e39249c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7209, -2.8895, -0.0000, -0.3594,  2.7514, -0.0000,  0.0000,  2.5047,\n",
       "         -0.0000,  0.0000,  0.7556, -0.0000, -1.6078,  4.6179,  0.7553, -0.0000,\n",
       "          1.9596],\n",
       "        [ 0.0000,  1.3095,  2.2952, -2.0256,  2.9392, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.4871, -0.0000,  0.0000, -0.0455,  1.7902,\n",
       "          2.2277],\n",
       "        [-0.7053,  0.3020, -0.0000, -0.5145, -0.6913, -0.0000, -0.0555,  1.4778,\n",
       "          0.5415, -1.0202, -0.5593, -2.5779, -1.6078,  0.0000, -0.0455,  1.7902,\n",
       "          0.0000],\n",
       "        [-0.0000, -0.0000, -0.2677, -4.4590, -0.2568,  0.0000, -0.0000,  3.3280,\n",
       "          1.5904, -1.4273, -1.6320, -0.0000,  1.7654, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a30a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aca94770",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_size, conts.shape[1], 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bff44265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41d3f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06f9acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1b10d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.56661701\n",
      "epoch:  26  loss: 10.91414452\n",
      "epoch:  51  loss: 10.22180653\n",
      "epoch:  76  loss: 9.74221516\n",
      "epoch: 101  loss: 9.18559933\n",
      "epoch: 126  loss: 8.43100357\n",
      "epoch: 151  loss: 7.42760420\n",
      "epoch: 176  loss: 6.23030090\n",
      "epoch: 201  loss: 5.07308149\n",
      "epoch: 226  loss: 4.21146965\n",
      "epoch: 251  loss: 3.89457393\n",
      "epoch: 276  loss: 3.78478384\n",
      "epoch: 300  loss: 3.70921564\n",
      "\n",
      "Duration: 217 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aef1cd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.66840959\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71fa2a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   4.8870   2.9000   1.9870\n",
      " 2.  26.0291   5.7000  20.3291\n",
      " 3.   5.1969   7.7000   2.5031\n",
      " 4.  14.2701  12.5000   1.7701\n",
      " 5.   5.1409   4.1000   1.0409\n",
      " 6.   4.5229   5.3000   0.7771\n",
      " 7.   5.0878   3.7000   1.3878\n",
      " 8.  13.3887  14.5000   1.1113\n",
      " 9.   3.8790   5.7000   1.8210\n",
      "10.  10.1431  10.1000   0.0431\n",
      "11.   4.4735   4.5000   0.0265\n",
      "12.   3.7195   6.1000   2.3805\n",
      "13.   6.4527   6.9000   0.4473\n",
      "14.  13.9916  14.1000   0.1084\n",
      "15.   4.9263   4.5000   0.4263\n",
      "16.  26.8691  34.1000   7.2309\n",
      "17.   5.1708  12.5000   7.3292\n",
      "18.   2.9231   4.1000   1.1769\n",
      "19.  12.1087   8.5000   3.6087\n",
      "20.   6.2867   5.3000   0.9867\n",
      "21.  14.0538  11.3000   2.7538\n",
      "22.   8.7881  10.5000   1.7119\n",
      "23.  15.1750  15.3000   0.1250\n",
      "24.  15.0359  14.9000   0.1359\n",
      "25.  36.4113  49.5700  13.1587\n",
      "26.   4.5704   5.3000   0.7296\n",
      "27.   3.7325   3.7000   0.0325\n",
      "28.   7.6584   6.5000   1.1584\n",
      "29.  13.9284  14.1000   0.1716\n",
      "30.   4.7594   4.9000   0.1406\n",
      "31.   5.8332   3.7000   2.1332\n",
      "32.  40.4321  38.6700   1.7621\n",
      "33.  11.2632  12.5000   1.2368\n",
      "34.  15.4043  16.5000   1.0957\n",
      "35.   5.8653   5.7000   0.1653\n",
      "36.   7.1005   8.9000   1.7995\n",
      "37.  21.6296  22.1000   0.4704\n",
      "38.   7.2645  12.1000   4.8355\n",
      "39.   8.3759  10.1000   1.7241\n",
      "40.   4.4956   3.3000   1.1956\n",
      "41.   9.7008   8.5000   1.2008\n",
      "42.  10.6850   8.1000   2.5850\n",
      "43.  14.1111  14.5000   0.3889\n",
      "44.   7.3293   4.9000   2.4293\n",
      "45.   8.7452   8.5000   0.2452\n",
      "46.   9.2802  12.1000   2.8198\n",
      "47.  25.1478  23.7000   1.4478\n",
      "48.   3.6669   3.7000   0.0331\n",
      "49.   9.6348   9.3000   0.3348\n",
      "50.  13.2468   8.1000   5.1468\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(50):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3337b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd584cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_size, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_size])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_size))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e547a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_size, 6, 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df978da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n",
    "model2.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a6e14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # pass in the name of the new model\n",
    "    # INPUT NEW DATA\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PREPROCESS THE DATA\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # We can skip the .astype(category) step since our fields are small,\n",
    "    # and encode them right away\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts)\n",
    "    print(f'\\nThe predicted fare amount is ${z.item():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9845476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the pickup latitude?  40.2\n",
      "What is the pickup longitude? -73.8\n",
      "What is the dropoff latitude?  40.12\n",
      "What is the dropoff longitude? -45.6\n",
      "How many passengers? 7\n",
      "What is the pickup date and time?\n",
      "Format as YYYY-MM-DD HH:MM:SS     2022-05-13 16:12:34\n",
      "\n",
      "The predicted fare amount is $3966.79\n"
     ]
    }
   ],
   "source": [
    "z = test_data(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545020d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
